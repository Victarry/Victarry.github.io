<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="https://victarry.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://victarry.github.io/" rel="alternate" type="text/html" /><updated>2023-05-05T11:11:24+00:00</updated><id>https://victarry.github.io/feed.xml</id><title type="html">Victarry’s Blog</title><subtitle></subtitle><author><name>Zhenhuan Liu</name><email>nkulzh16@gmail.com</email></author><entry><title type="html">使用Nginx在个人服务器上搭载静态网站</title><link href="https://victarry.github.io/2023/04/06/nginx.html" rel="alternate" type="text/html" title="使用Nginx在个人服务器上搭载静态网站" /><published>2023-04-06T00:00:00+00:00</published><updated>2023-04-06T00:00:00+00:00</updated><id>https://victarry.github.io/2023/04/06/nginx</id><content type="html" xml:base="https://victarry.github.io/2023/04/06/nginx.html">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_nginx的作用&quot;&gt;Nginx的作用&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Nginx是一款高性能的Web服务器和反向代理服务器，其主要作用如下：&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;提供Web服务器功能：Nginx可以作为静态或动态内容的Web服务器，为Web应用程序提供服务。它可以处理静态文件和动态请求，支持FastCGI、uWSGI、SCGI和WSGI等协议，并提供缓存和压缩等功能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;反向代理服务器：Nginx还可以作为反向代理服务器，用于将请求转发到后端服务器（如应用服务器、数据库服务器等），并将响应返回给客户端。反向代理可以提高Web应用程序的可靠性、安全性和可扩展性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;负载均衡器：Nginx可以作为负载均衡器，将请求分发到多个后端服务器，以提高Web应用程序的性能和可扩展性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HTTPS代理服务器：Nginx还可以作为HTTPS代理服务器，用于为后端服务器提供SSL/TLS加密功能，保护Web应用程序的安全性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;总之，Nginx是一个灵活、高效、可靠的Web服务器和反向代理服务器，具有处理大量并发连接和高负载的能力，被广泛用于Web应用程序的部署和扩展。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_nginx配置文件简介&quot;&gt;nginx配置文件简介&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Nginx配置文件通常在 `/etc/nginx/`下, 常见文件组织结构如下:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;/etc/nginx/
├── conf.d
├── fastcgi.conf
├── fastcgi_params
├── koi-utf
├── koi-win
├── mime.types
├── modules-available
├── modules-enabled
├── nginx.conf // 顶层配置文件，包括worker,log位置等
├── proxy_params
├── scgi_params
├── sites-available
│   ├── default
│   └── starriest.top
├── sites-enabled // 启用的sites
│   └── starriest.top
├── snippets
│   ├── fastcgi-php.conf
│   └── snakeoil.conf
├── uwsgi_params
└── win-utf&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;可以查看/etc/nginx/sites-enabled/default文件，进行配置&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;ngxin log一般在/var/log/nginx/access.log和/var/log/nginx/error.log中&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_默认nginx配置文件解读&quot;&gt;默认nginx配置文件解读&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;##
# You should look at the following URL's in order to grasp a solid understanding
# of Nginx configuration files in order to fully unleash the power of Nginx.
# https://www.nginx.com/resources/wiki/start/
# https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/
# https://wiki.debian.org/Nginx/DirectoryStructure
#
# In most cases, administrators will remove this file from sites-enabled/ and
# leave it as reference inside of sites-available where it will continue to be
# updated by the nginx packaging team.
#
# This file will automatically load configuration files provided by other
# applications, such as Drupal or Wordpress. These applications will be made
# available underneath a path with that package name, such as /drupal8.
#
# Please see /usr/share/doc/nginx-doc/examples/ for more detailed examples.
##

# Default server configuration
#
server {
	listen 80 default_server;
	listen [::]:80 default_server;

	# SSL configuration
	#
	# listen 443 ssl default_server;
	# listen [::]:443 ssl default_server;
	#
	# Note: You should disable gzip for SSL traffic.
	# See: https://bugs.debian.org/773332
	#
	# Read up on ssl_ciphers to ensure a secure configuration.
	# See: https://bugs.debian.org/765782
	#
	# Self signed certs generated by the ssl-cert package
	# Don't use them in a production server!
	#
	# include snippets/snakeoil.conf;

	root /var/www/html;

	# Add index.php to the list if you are using PHP
	index index.html index.htm index.nginx-debian.html;

	server_name _;

	location / {
		# First attempt to serve request as file, then
		# as directory, then fall back to displaying a 404.
		try_files $uri $uri/ =404;
	}

	# pass PHP scripts to FastCGI server
	#
	#location ~ \.php$ {
	#	include snippets/fastcgi-php.conf;
	#
	#	# With php-fpm (or other unix sockets):
	#	fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
	#	# With php-cgi (or other tcp sockets):
	#	fastcgi_pass 127.0.0.1:9000;
	#}

	# deny access to .htaccess files, if Apache's document root
	# concurs with nginx's one
	#
	#location ~ /\.ht {
	#	deny all;
	#}
}


# Virtual Host configuration for example.com
#
# You can move that to a different file under sites-available/ and symlink that
# to sites-enabled/ to enable it.
#
#server {
#	listen 80;
#	listen [::]:80;
#
#	server_name example.com;
#
#	root /var/www/example.com;
#	index index.html;
#
#	location / {
#		try_files $uri $uri/ =404;
#	}
#}&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;server定义了一个server block, 可以处理对应端口接受到的请求, 并进行相应返回。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;nginx会根据server_name和请求Header中的host选择匹配到哪个具体的server block, 如果server_name是_的话，那么没有被匹配到请求就会被转发到此server.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;listen定义了server对应的端口，如果是default_server的话，那么该端口下没有被server_name匹配的请求会被转发到该defult server, 无论default server的server_name是否是_，一个端口只能有一个default server, 如果没有指定default server, 那么按照顺序，第一个server会被作为defualt server.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;index 默认情况下，nginx的index指令的值为`index.html index.htm`。这意味着当客户端请求一个目录时，Nginx将首先检查该目录下是否存在index.html文件，如果不存在，则继续检查是否存在index.htm文件。如果两个文件都不存在，则Nginx将返回目录列表或403 Forbidden错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;location&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_nginx配置tls协议启用https&quot;&gt;Nginx配置TLS协议(启用HTTPS)&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;要在Nginx中启用SSL加密，需要执行以下步骤：&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;为服务器获取SSL证书：您需要从信任的证书颁发机构（CA, 例如ZeroSSL）购买SSL证书，或使用自签名证书来启用SSL。这通常需要指定域名和服务器的详细信息。 利用acme.sh可以定期更新证书.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将SSL证书文件和私钥文件放置在服务器上：您需要将证书文件（通常是.crt格式）和私钥文件（通常是.key格式）放置在服务器上的安全位置。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;配置Nginx以使用SSL：在Nginx的server块中，添加以下配置来启用SSL：&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;server {
    listen       443 ssl;
    server_name  example.com;
    ssl_certificate      /path/to/certificate.crt;
    ssl_certificate_key  /path/to/private.key;
    ...
}&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;这将使Nginx监听HTTPS的443端口，并使用指定的证书和私钥文件进行SSL加密。&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重新加载Nginx配置：在更改Nginx配置后，需要重新加载Nginx以使其生效。您可以使用以下命令重新加载Nginx：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;sudo systemctl reload nginx&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;如果配置存在错误，则使用以下命令检查错误：
sudo nginx -t
如果检查结果没有错误，可以重新加载Nginx。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_可能的问题&quot;&gt;可能的问题&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;服务器提供商使用了防火墙，使用`telnet host port`查看是否可以连接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;大陆封禁了443端口的流量(可能)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name><email>nkulzh16@gmail.com</email></author></entry><entry><title type="html">自建Xray服务器教程</title><link href="https://victarry.github.io/2023/04/04/xray-config.html" rel="alternate" type="text/html" title="自建Xray服务器教程" /><published>2023-04-04T00:00:00+00:00</published><updated>2023-04-04T00:00:00+00:00</updated><id>https://victarry.github.io/2023/04/04/xray-config</id><content type="html" xml:base="https://victarry.github.io/2023/04/04/xray-config.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;本节介绍了如何搭建xray服务器用于科学上网。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_v2ray和xray简介&quot;&gt;1. V2ray和Xray简介&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Project V是一个工具集合，可以实现专属的基础通信网络。Project V 的核心工具称为V2Ray，其主要负责网络协议和功能的实现，与其它Project V通信。V2Ray 可以单独运行，也可以和其它工具配合，以提供简便的操作流程。从V2ray上面衍生了各种GUI程序被用于客户端。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;2020年，V2ray原作者停止更新 &lt;a href=&quot;https://github.com/v2fly/v2ray-core&quot;&gt;V2Ray&lt;/a&gt;仓库 ，由 &lt;a href=&quot;https://www.v2fly.org/&quot;&gt;V2fly&lt;/a&gt;接管&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;2020年11月，因为开源许可证等原因XTLS被V2Ray社区从V2ray core移除，VLESS及XTLS的作者和支持者基于V2Ray另行组建了Project X组织。Xray-core 是 v2ray-core 的超集，具有更好的整体性能和 XTLS 等一系列增强，且完全兼容 v2ray-core 的功能及配置。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_安装&quot;&gt;2. 安装&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_服务器安装&quot;&gt;2.1. 服务器安装&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://xtls.github.io/document/install.html#%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC&quot;&gt;官方教程&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;直接版本:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;bash -c &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-k&quot;&gt;$(&lt;/span&gt;curl -L https://github.com/XTLS/Xray-install/raw/main/install-release.sh&lt;span class=&quot;tok-k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;&lt;/span&gt; @ install&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;配置等相关内容如下:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;installed: /etc/systemd/system/xray.service
installed: /etc/systemd/system/xray@.service

installed: /usr/local/bin/xray
installed: /usr/local/etc/xray/*.json

installed: /usr/local/share/xray/geoip.dat
installed: /usr/local/share/xray/geosite.dat

installed: /var/log/xray/access.log
installed: /var/log/xray/error.log&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_客户端安装&quot;&gt;2.2. 客户端安装&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Windows: Clash等&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mac: &lt;a href=&quot;https://github.com/yanue/V2rayU/tree/newui&quot;&gt;V2rayU&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_服务器配置xray&quot;&gt;3. 服务器配置Xray&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_最简单版本-任意端口不采用fallback&quot;&gt;3.1. 最简单版本: 任意端口，不采用fallback&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;服务器配置&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span&gt;&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
 &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;log&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;access&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;/etc/v2ray/access.log&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;error&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;/etc/v2ray/error.log&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;loglevel&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;None&amp;quot;&lt;/span&gt;
  &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
  &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;inbounds&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[{&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;port&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;10086&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;protocol&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;vmess&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;clients&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[{&lt;/span&gt; &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;70bb5a14-d4f1-11ed-afa1-0242ac120002&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;alterId&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;level&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;}]&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;tok-p&quot;&gt;}],&lt;/span&gt;
   &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;outbounds&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[{&lt;/span&gt;
     &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;protocol&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;freedom&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{}&lt;/span&gt;
   &lt;span class=&quot;tok-p&quot;&gt;}]&lt;/span&gt;
&lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;port代表服务器监听端口&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;id采用UUID格式，可以使用`xray uuid`生成&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;启动服务端命令: xray run --config /etc/v2ray/config_base.json&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;客户端配置&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;log&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;error&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;loglevel&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;info&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;access&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;
  &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
  &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;inbounds&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;listen&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;0.0.0.0&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;protocol&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;socks&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;udp&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;auth&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;noauth&amp;quot;&lt;/span&gt;
      &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;port&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;1080&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;listen&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;0.0.0.0&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;protocol&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;http&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;timeout&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;360&lt;/span&gt;
      &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;port&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;1087&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;tok-p&quot;&gt;],&lt;/span&gt;
  &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;outbounds&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;mux&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;enabled&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;concurrency&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;8&lt;/span&gt;
      &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;protocol&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;vmess&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;streamSettings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;network&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;tcp&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;tcpSettings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;header&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;none&amp;quot;&lt;/span&gt;
          &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;security&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;none&amp;quot;&lt;/span&gt;
      &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;tag&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;proxy&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;vnext&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;
          &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;address&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;your-host-address&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;users&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;
              &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;70bb5a14-d4f1-11ed-afa1-0242ac120002&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;alterId&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;level&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;security&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;auto&amp;quot;&lt;/span&gt;
              &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;tok-p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;port&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;10086&lt;/span&gt;
          &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;tok-p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;tag&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;direct&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;protocol&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;freedom&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;domainStrategy&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;UseIP&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;userLevel&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;tag&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;block&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;protocol&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;blackhole&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;response&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;none&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;tok-p&quot;&gt;],&lt;/span&gt;
  &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;dns&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{},&lt;/span&gt;
  &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;routing&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;domainStrategy&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;AsIs&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;rules&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;tok-p&quot;&gt;},&lt;/span&gt;
  &lt;span class=&quot;tok-nt&quot;&gt;&amp;quot;transport&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;port与id需要与服务器保持一致&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;address输入服务器ip地址&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_vmess-web版本&quot;&gt;3.2. VMESS + Web版本&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;1.安装acme来获取ssl证书
&lt;a href=&quot;https://github.com/acmesh-official/acme.sh/wiki/%E8%AF%B4%E6%98%8E&quot;&gt;安装ACME&lt;/a&gt;
2. 配置服务器和nginx &lt;a href=&quot;https://xtls.github.io/document/level-0/ch07-xray-server.html#_7-1-%E5%8D%9A%E8%A7%82%E8%80%8C%E7%BA%A6%E5%8F%96-%E5%8E%9A%E7%A7%AF%E8%80%8C%E8%96%84%E5%8F%91&quot;&gt;xray官方教程&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_常见问题&quot;&gt;4. 常见问题&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/233boy/v2ray/issues/812&quot;&gt;VMessAEAD is enforced and a non VMessAEAD connection is received&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_调试相关&quot;&gt;5. 调试相关&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;查看logging信息, 在服务器开启logging, 设置loglevel=info&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;systemctl status查看服务信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;journalctl -u xray.service -b查看logging&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_相关链接&quot;&gt;6. 相关链接&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/V2Ray#:~:text=V2Ray%EF%BC%8C%E6%98%AFVictoria%20Raymond%E4%BB%A5%E5%8F%8A,%E4%B8%8E%E5%85%B6%E5%AE%83Project%20V%E9%80%9A%E4%BF%A1%E3%80%82&quot;&gt;V2ray Wikipedia简介&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/XTLS/Xray-examples&quot;&gt;V2ray Examples&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://toutyrater.github.io/&quot;&gt;V2Ray介绍博客&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://xtls.github.io/&quot;&gt;Project X&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name></author><summary type="html">本节介绍了如何搭建xray服务器用于科学上网。</summary></entry><entry><title type="html">Pytorch Dataset模块笔记</title><link href="https://victarry.github.io/2021/04/06/pytorch-dataset.html" rel="alternate" type="text/html" title="Pytorch Dataset模块笔记" /><published>2021-04-06T00:00:00+00:00</published><updated>2021-04-06T00:00:00+00:00</updated><id>https://victarry.github.io/2021/04/06/pytorch-dataset</id><content type="html" xml:base="https://victarry.github.io/2021/04/06/pytorch-dataset.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;对pytorch的 &lt;code&gt;nn.utils.data&lt;/code&gt; 模块进行分析和整理.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_dataset&quot;&gt;Dataset&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;目的是实现取出一个item的方法&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;Dataset分为map-style和iterable-style&lt;/p&gt;
&lt;div class=&quot;olist loweralpha&quot;&gt;
&lt;ol class=&quot;loweralpha&quot; type=&quot;a&quot;&gt;
&lt;li&gt;
&lt;p&gt;map-style通过重载 &lt;code&gt;&lt;em&gt;getitem&lt;/em&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;em&gt;len&lt;/em&gt;&lt;/code&gt; 来实现随机访问&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;iterable-style通过重载 &lt;code&gt;&lt;em&gt;iter&lt;/em&gt;&lt;/code&gt; 手动实现 stream&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于ImageFolder的数据集, 适合用于map-style的Dataest&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_dataset中类的使用&quot;&gt;Dataset中类的使用&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;ConcatDataset(datasets)&lt;/code&gt; , 将多个datasets concat在一起, 每次返回其中一个dataset中的一个item&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_自定义dataset中的注意事项&quot;&gt;自定义Dataset中的注意事项&lt;/h3&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;设置整个dataset包含的所有数据,例如一个文件夹下面的路径 (注意过滤文件后缀, 防止非图像文件混入)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实现如何read一个,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;设置transform&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_dataloader&quot;&gt;DataLoader&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;sampler&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch_sampler&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;num_workers&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;collate_fn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;pin_memory&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;drop_last&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;worker_init_fn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;multiprocessing_context&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;prefetch_factor&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;persistent_workers&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;如果dataset是iterable-style, 那么必须有 &lt;code&gt;shuffle=False&lt;/code&gt;, &lt;code&gt;sampler=None&lt;/code&gt;, &lt;code&gt;batch_sampler=None&lt;/code&gt;,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;根据batch_size决定采用sampler还是batch_sampler&lt;/p&gt;
&lt;div class=&quot;olist loweralpha&quot;&gt;
&lt;ol class=&quot;loweralpha&quot; type=&quot;a&quot;&gt;
&lt;li&gt;
&lt;p&gt;如果 &lt;code&gt;batch_size=None&lt;/code&gt;, 那么使用sampler, 每次返回一个index&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;sampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;collate_fn&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist lowerroman&quot;&gt;
&lt;ol class=&quot;lowerroman&quot; type=&quot;i&quot;&gt;
&lt;li&gt;
&lt;p&gt;如果 &lt;code&gt;shuffle=False&lt;/code&gt; , 那么采用 &lt;code&gt;SequentialSampler&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果 &lt;code&gt;shuffle=True&lt;/code&gt; , 那么采用 &lt;code&gt;RandomSampler&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果要自己实现 &lt;code&gt;Sampler&lt;/code&gt;, 那么要实现 &lt;code&gt;&lt;em&gt;iter&lt;/em&gt;&lt;/code&gt;, 其中每次返回一个index, 同时设置 &lt;code&gt;shuffle=False&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果 &lt;code&gt;batch_size&lt;/code&gt; 不是 &lt;code&gt;None&lt;/code&gt;, 那么采用 batch_sampler, 同时使用collate_fn处理. (注意: &lt;strong&gt;batch_size默认值为1&lt;/strong&gt; )&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;dataset_iter&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch_sampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;collate_fn&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;dataset_iter&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist lowerroman&quot;&gt;
&lt;ol class=&quot;lowerroman&quot; type=&quot;i&quot;&gt;
&lt;li&gt;
&lt;p&gt;如果 &lt;code&gt;batch_sampler&lt;/code&gt; 是 &lt;code&gt;None&lt;/code&gt; , 那么采用automatic batching, 使用默认的 &lt;code&gt;sampler&lt;/code&gt; 对应的 &lt;code&gt;batch_sampler&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果传入的是 &lt;code&gt;sampler&lt;/code&gt; 不是 &lt;code&gt;None&lt;/code&gt; , 那么将采用传入的 &lt;code&gt;sampler&lt;/code&gt; 对应的 &lt;code&gt;batch_sampler&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果要自己实现 &lt;code&gt;batch_sampler&lt;/code&gt;, 那么要实现 &lt;code&gt;&lt;em&gt;iter&lt;/em&gt;&lt;/code&gt;, 其中每次返回一个batch的indexs, 同时设置 &lt;code&gt;shuffle=False, sampler=None, batch_size=1, drop_last=False&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_sampler&quot;&gt;Sampler&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;shuffle=False&lt;/code&gt; 时 , pytorch默认的sampler&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;tok-nc&quot;&gt;RandomSampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Sampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;]):&lt;/span&gt;
    &lt;span class=&quot;tok-sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;tok-sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Samples elements randomly. If without replacement, then sample from a shuffled dataset.&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;    If with replacement, then user can specify :attr:`num_samples` to draw.&lt;/span&gt;

&lt;span class=&quot;tok-sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        data_source (Dataset): dataset to sample from&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        replacement (bool): samples are drawn on-demand with replacement if ``True``, default=``False``&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        num_samples (int): number of samples to draw, default=`len(dataset)`. This argument&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;            is supposed to be specified only when `replacement` is ``True``.&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        generator (Generator): Generator used in sampling.&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;tok-n&quot;&gt;data_source&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;Sized&lt;/span&gt;
    &lt;span class=&quot;tok-n&quot;&gt;replacement&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;bool&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;data_source&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;Sized&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;replacement&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;tok-n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;data_source&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;data_source&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;replacement&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;replacement&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;_num_samples&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;num_samples&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;replacement&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;replacement should be a boolean value, but got &amp;quot;&lt;/span&gt;
                            &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;replacement=&lt;/span&gt;&lt;span class=&quot;tok-si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;replacement&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;_num_samples&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;replacement&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;With replacement=False, num_samples should not be specified, &amp;quot;&lt;/span&gt;
                             &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;since a random permute will be performed.&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_samples&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;num_samples should be a positive integer &amp;quot;&lt;/span&gt;
                             &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;value, but got num_samples=&lt;/span&gt;&lt;span class=&quot;tok-si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;tok-nd&quot;&gt;@property&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-nf&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# dataset size might change at runtime&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;_num_samples&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;data_source&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;_num_samples&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-fm&quot;&gt;__iter__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;data_source&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;manual_seed&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;((),&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;random_&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()))&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;replacement&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_samples&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;tok-k&quot;&gt;yield from&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;yield from&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_samples&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;yield from&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;randperm&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-fm&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_samples&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_batch-sampler&quot;&gt;Batch Sampler&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;pytorch默认的batch_sampler,&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;tok-nc&quot;&gt;BatchSampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Sampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;]]):&lt;/span&gt;
    &lt;span class=&quot;tok-sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;tok-sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Wraps another sampler to yield a mini-batch of indices.&lt;/span&gt;

&lt;span class=&quot;tok-sd&quot;&gt;    Args:&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        sampler (Sampler or Iterable): Base sampler. Can be any iterable object&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        batch_size (int): Size of mini-batch.&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        drop_last (bool): If ``True``, the sampler will drop the last batch if&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;            its size would be less than ``batch_size``&lt;/span&gt;

&lt;span class=&quot;tok-sd&quot;&gt;    Example:&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        &amp;gt;&amp;gt;&amp;gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        &amp;gt;&amp;gt;&amp;gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]&lt;/span&gt;
&lt;span class=&quot;tok-sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;sampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;Sampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;drop_last&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# Since collections.abc.Iterable does not check for `__getitem__`, which&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# is one way for an object to be an iterable, we don&amp;#39;t do an `isinstance`&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# check here.&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;_int_classes&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;or&lt;/span&gt; \
                &lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;batch_size should be a positive integer value, &amp;quot;&lt;/span&gt;
                             &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;but got batch_size=&lt;/span&gt;&lt;span class=&quot;tok-si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;drop_last&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;drop_last should be a boolean value, but got &amp;quot;&lt;/span&gt;
                             &lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;drop_last=&lt;/span&gt;&lt;span class=&quot;tok-si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;drop_last&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sampler&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;sampler&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;drop_last&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;drop_last&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-fm&quot;&gt;__iter__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;tok-k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;
                &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;drop_last&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-fm&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# Can only be called if self.sampler has __len__ implemented&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# We cannot enforce this condition, so we turn off typechecking for the&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# implementation below.&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;drop_last&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt;  &lt;span class=&quot;tok-c1&quot;&gt;# type: ignore&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sampler&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch_size&lt;/span&gt;  &lt;span class=&quot;tok-c1&quot;&gt;# type: ignore&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_collate_fn&quot;&gt;Collate_fn&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;输入一个大小为batch_size的list, 包含了每次从dataset中sampler得到数据, 目的是
NLP任务中, 由于句子长短不同常需要进行padding,使得所有句子token长度一致.
CV任务中, 预处理时会将所有图片resize到固定大小, 一般不需要特殊处理.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Pytorch默认collate_fn实现(automatic batching下, 即batch_sampler=None, batch_size!=None)&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-nf&quot;&gt;default_collate&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;tok-sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;tok-sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Puts each data field into a tensor with outer dimension batch size&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;tok-n&quot;&gt;elem_type&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;get_worker_info&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-c1&quot;&gt;# If we&amp;#39;re in a background process, concatenate directly into a&lt;/span&gt;
            &lt;span class=&quot;tok-c1&quot;&gt;# shared memory tensor to avoid an extra copy&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;numel&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;storage&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;_new_shared&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem_type&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-vm&quot;&gt;__module__&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;numpy&amp;#39;&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem_type&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-vm&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;str_&amp;#39;&lt;/span&gt; \
            &lt;span class=&quot;tok-ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem_type&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-vm&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;string_&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem_type&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-vm&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;ndarray&amp;#39;&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem_type&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-vm&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;memmap&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-c1&quot;&gt;# array of string classes and object&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;np_str_obj_array_pattern&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;default_collate_err_msg_format&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;

            &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;default_collate&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;as_tensor&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;():&lt;/span&gt;  &lt;span class=&quot;tok-c1&quot;&gt;# scalars&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;as_tensor&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;float64&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;int_classes&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;string_classes&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;container_abcs&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Mapping&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;default_collate&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;hasattr&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;_fields&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;tok-c1&quot;&gt;# namedtuple&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem_type&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;default_collate&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;samples&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;container_abcs&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Sequence&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# check to make sure that the elements in batch have consistent size&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;elem_size&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem_size&lt;/span&gt; &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;RuntimeError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;each element in list of batch should be of equal size&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;transposed&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;default_collate&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;samples&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;transposed&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;default_collate_err_msg_format&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;elem_type&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name></author><summary type="html">对pytorch的 nn.utils.data 模块进行分析和整理.</summary></entry><entry><title type="html">A Few Useful Things to Know about Machine Learning</title><link href="https://victarry.github.io/2021/03/18/useful-things-for-ML.html" rel="alternate" type="text/html" title="A Few Useful Things to Know about Machine Learning" /><published>2021-03-18T00:00:00+00:00</published><updated>2021-03-18T00:00:00+00:00</updated><id>https://victarry.github.io/2021/03/18/useful-things-for-ML</id><content type="html" xml:base="https://victarry.github.io/2021/03/18/useful-things-for-ML.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;对于 &lt;a href=&quot;https://www.astro.caltech.edu/~george/ay122/cacm12.pdf&quot;&gt;A Few Useful Things to Know about Machine Learning&lt;/a&gt; 的总结,这是一篇很有启发的文章,总结了机器学习领域一些本质且普遍的概念.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;quoteblock&quot;&gt;
&lt;blockquote&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;Machine Learning = Representation + Evaluation + Optimization&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_its-generalization-that-counts&quot;&gt;It’s Generalization that Counts&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;测试集留到最后→ 根据测试集调参会产生Contamination&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;cross validation&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;虽然知道但其实还是很神奇的事情 → &lt;em&gt;We don’t have access to the function
we want to optimize.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_data-alone-is-not-enough&quot;&gt;Data Alone is Not Enough&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;为了使Generatalization成立，必须使用某些Knowledge或者Assumption&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;No Free Lunch&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;[&lt;a href=&quot;https://medium.com/@LeonFedden/the-no-free-lunch-theorem-62ae2c3ed10c&quot; class=&quot;bare&quot;&gt;https://medium.com/@LeonFedden/the-no-free-lunch-theorem-62ae2c3ed10c&lt;/a&gt;](&lt;a href=&quot;https://medium.com/@LeonFedden/the-no-free-lunch-theorem-62ae2c3ed10c&quot; class=&quot;bare&quot;&gt;https://medium.com/@LeonFedden/the-no-free-lunch-theorem-62ae2c3ed10c&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Real World → Simple Assumption&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;The functions we want to learn in the real world are not drawn
uniformly from the set of all mathematically possible functions! In
fact, very general assumptions—like smoothness, similar examples having
similar classes, limited dependences, or limited complexity—are often
enough to do very well, and this is a large part of why machine learning
has been so successful.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Induction and Deduction&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Like deduction, induction (what learners do) is a knowledge lever: it
turns a small amount of input knowledge into a large amount of output
knowledge. Induction is a vastly more powerful lever than deduction,
requiring much less input knowledge to produce useful results, but it
still needs more than zero input knowledge to work.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Deductoin: The conclusion is always true as long as the premises are
true.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;             **(Idea  → Observation → Conclusion)**&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Induction: the quality of the idea or model or theory depends on the
quality of the observations and analysis.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;            **(Observation → Analysis → Theory)**&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://danielmiessler.com/blog/the-difference-between-deductive-and-inductive-reasoning/&quot; class=&quot;bare&quot;&gt;https://danielmiessler.com/blog/the-difference-between-deductive-and-inductive-reasoning/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Representation → Knowledge&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;The most useful learners in this regard are those that do not just have
assumptions hardwired into them, but allow us to state them explicitly,
vary them widely, and incorporate them automatically into the learning&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learning from Nature&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Machine learning is not magic; it cannot get something from nothing.
What it does is get more from less.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Learners combine knowledge with data to grow programs.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_overfitting-has-many-faces&quot;&gt;Overfitting Has Many Faces&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Generalization Error → Bias + Variance&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Variance: 多个learner得到的结果不同&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Bias: expected estimator与grountruth的偏差&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;模型参数角度: (频率派解释？即\(\theta\)为定值)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[\begin{aligned}  MSE  &amp;amp;= E[(\hat \theta_m-\theta)^2] \\  &amp;amp; = Bias(\hat \theta_m)^2 + Var(\hat \theta_m) \end{aligned} \]
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模型capacity越大，variance越大，bias越小。 → 由于inductive bias越小？&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;例如神经网络可以拟合任何函数，那么variance就很大&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;A linear learner has high bias, because when the frontier between two
classes is not a hyperplane the learner is unable to induce it. Decision
trees do not have this problem because they can represent any Boolean
function, but on the other hand they can suffer from high variance:
decision trees learned on different training sets generated by the same
phenomenon are often very different,when in fact they should be the
same.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Variance/Capacity越大的模型越需要更多的数据来减小Variance&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;一个rule-based下的数据集，C4.5决策树在数据量小的时候不如naive bayes&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Situations like this are common in machine learning: strong false
assumptions can be better than weak true ones, because a learner with
the latter needs more data to avoid overfitting.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;regularization technique&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;一种理解: 限制模型的解空间，可以约束variance?&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;statistical significance test&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;trade-off&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;It is easy to avoid overfitting (variance) by falling into the opposite
error of underfitting (bias). Simultaneously avoiding both requires
learning a perfect classifier, and short of knowing it in advance there
is no single technique that will always do best (no free lunch).&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Noise and overfitting&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;noise会使overfitting加重，但不是根本原因&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;This can indeed aggravate overfitting, by making the learner draw a
capricious frontier to keep those examples on what it thinks is the
right side. But severe overfitting can occur even in the absence of
noise.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;multiple testing&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_intuition-fails-in-high-dimensions&quot;&gt;Intuition Fails in High Dimensions&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;On the Surprising Behavior of Distance Metrics in High Dimensional
Space&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;仅次于overfitting的第二大问题 → &lt;em&gt;curse of dimension&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;维度越多 → 数据覆盖范围越小&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Generalizing correctly becomes exponentially harder as the
dimensionality (number of features) of the examples grows, because a
fixed-size training set covers a dwindling fraction of the input space.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;假设100维度，10万亿(1e12)个数据, 只能覆盖\(1e^{-18}\)的空间&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;难以进行有效的距离度量 → 基于相似性的模型break down&lt;/p&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;高维度下noise，覆盖了关联特征之间的影响&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;即使所有feature
relevant，一个数据点相同距离的数据点的随着维度指数级增长&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Curse of Dimension → PRML第一章&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;In high dimensions, most of the mass of a multivariate Gaussian
distribution is not near the mean, but in an increasingly distant
``shell'' around it; and most of the volume of a highdimensional orange
is in the skin, not the pulp.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;If a constant number of examples is distributed uniformly in a
high-dimensional hypercube, beyond some dimensionality most examples are
closer to a face of the hypercube than to their nearest neighbor.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;If we approximate a hypersphere by inscribing it in a hypercube, in
high dimensions almost all the volume of the hypercube is outside the
hypersphere. This is bad news for machine learning, where shapes of one
type are often approximated by shapes of another.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特征不是越多越好 →
多一个特征至少不会损失模型性能(哪怕它没有提供额外信息) ❌&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Naively, one might think that gathering more features never hurts,
since at worst they provide no new information about the class. But in
fact their benefits may be outweighed by the curse of dimensionality.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;blessing of non uniformity&lt;/em&gt; → 流形学习&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_theoretical-guarantees-are-not-what-they-seem&quot;&gt;Theoretical Guarantees Are Not What They Seem&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Theory → PAC Learnable&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the major developments of recent decades has been the realization
that in fact we can have guarantees on the results of induction,
particularly if we are willing to settle for probabilistic guarantees.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Take with a large grain of salt&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;given infinite data, the learner is guaranteed to output the correct
classifier.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;This is reassuring, but it would be rash to choose one learner over
another because of its asymptotic guarantees. In practice, we are seldom
in the asymptotic regime (also known as ``asymptopia''). And, because of
the bias-variance trade-off I discussed earlier, *if learner A is better
than learner B given infinite data, B is often better than A given
finite data.*&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Theory只是Theory&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;The main role of theoretical guarantees in machine learning is not as a
criterion for practical decisions, but as a source of understanding and
driving force for algorithm design&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Learning is a complex phenomenon, and just because a learner has a
theoretical justification and works in practice does not mean the former
is the reason for the latter.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_feature-engineering-is-the-key&quot;&gt;Feature Engineering is The Key&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;machine learning is not a one-shot process of building a dataset and
running a learner, but rather an iterative process of running the
learner, analyzing the results, modifying the data and/or the learner,
and repeating.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Learning is often the quickest part of this, but that is because we
have already mastered it pretty well! Feature engineering is more
difficult because it is domain-specific, while learners can be largely
general purpose. However, there is no sharp frontier between the two,
and this is another reason the *most useful learners are those that
facilitate incorporating knowledge.*&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;bear in mind that features that &lt;strong&gt;look irrelevant in isolation may be
relevant in combination&lt;/strong&gt;. For example, if the class is an XOR of k input
features, each of them by itself carries no information about the class.
(If you want to annoy machine learners, bring up XOR.) On the other
hand, running a learner with a very large number of features to find out
which ones are useful in combination may be too time-consuming, or cause
overfitting. So there is ultimately no replacement for the smarts you
put into feature engineering.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deep learning is feature engineering(我自己说的)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_more-data-beats-a-clevrer-algorithm&quot;&gt;More Data Beats a Clevrer Algorithm&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;As a rule of thumb, a dumb algorithm with lots and lots of data beats
a clever one with modest amounts of it.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scalability: 数据多→ 训练时间长&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;好的模型的payoff其实并没有那么大&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;All learners essentially work by grouping nearby examples into the same
class; the key difference is in the meaning of ``nearby.''&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;With nonuniformly distributed data, learners can produce widely
different frontiers while still making the same predictions in the
regions that matter (those with a substantial number of training
examples, and therefore also where most test examples are likely to
appear).&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;This also helps explain why powerful learners can be unstable but
still accurate.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;很多不同的模型可以达到相同的效果(由于训练数据有限/空间稀疏)&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;As a rule, it pays to try the simplest learners first (for example,
naïve Bayes before logistic regression, k-nearest neighbor before
support vector machines)&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两种模型: 参数模型 vs. 非参数模型&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Learners can be divided into two major types: those whose representation
has a fixed size, like linear classifiers, and those whose
representation can grow with the data, like decision trees.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;payoff在哪里&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;由于实际数据有限 + 维度灾难，clever algorithm是能最大化利用数据的算法&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;C&lt;em&gt;lever algorithmsthose that make the most of the data and computing
resources availableoften pay off in the end, provided you are willing to
put in the effort.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最重要的还是人们的insight&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;In research papers, learners are typically compared on measures of
accuracy and computational cost. But human effort saved and insight
gained, although harder to measure, are often more important. This
favors learners that produce human-understandable output (for example,
rule sets). And the organizations that make the most of machine learning
are those that have in place an infrastructure that makes experimenting
with many different learners, data sources, and learning problems easy
and efficient, and where there is a close collaboration between machine
learning experts and application domain ones.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_learn-many-models-not-just-one&quot;&gt;Learn Many Models, Not Just One&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;variants of one model → many variants of many model&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;model ensembles&lt;/p&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;bagging&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;each classifier with a resampled dataset. → &lt;strong&gt;&lt;em&gt;greatly decrease variance,
slightly increase bias&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;boosting&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;training examples have weights, and these are varied so that *each new
classifier focuses on the examples the previous ones tended to get
wrong.*&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;stacking&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;the outputs of individual classifiers become the inputs of a
``higher-level'' learner that figures out how best to combine them.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;(有点像multi-scale的感觉?)&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bayesian model averaging vs. Ensemble&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Ensembles change the hypothesis space (for example, from single
decision trees to linear combinations of them), and can take a wide
variety of forms. BMA assigns weights to the hypotheses in the original
space according to a fixed formula.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;BMA weights are extremely different from those produced by (say)
bagging or boosting: the latter are fairly even, while the former are
extremely skewed, to the point where the single highest-weight
classifier usually dominates, making BMA effectively equivalent to just
selecting it. 8 A practical consequence of this is that, *while model
ensembles are a key part of the machine learning toolkit, BMA is seldom
worth the trouble.*&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_simplicity-does-not-imply-accuracy&quot;&gt;Simplicity Does not Imply Accuracy&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;奥卡姆剃刀 → 如无必要，勿增实体 →
相同训练误差下应该选择简单模型的泛化性更好(❌)&lt;/p&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Model Ensembles&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;The generalization error of a boosted ensemble continues to improve by
adding classifiers even after the training error has reached zero.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SVM (为什么呢?)&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another counterexample is support vector machines, which can effectively
have an infinite number of parameters without overfitting.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实际上，并没有直接联系&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Conversely, the function sign(sin(ax)) can discriminate an arbitrarily
large, arbitrarily labeled set of points on the x axis, even though it
has only one parameter.&lt;/em&gt; (怎么确定这个a呢)&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;complexity → size of hypothesis space&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;复杂度与模型搜索&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;A further complication arises from the fact that few learners search
their hypothesis space exhaustively. A learner with a larger hypothesis
space that tries fewer hypotheses from it is less likely to overfit than
one that tries more hypotheses from a smaller space. As Pearl points
out, the size of the hypothesis space is only a rough guide to what
really matters for relating training and test error: the procedure by
which a hypothesis is chosen.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;奥卡姆剃刀 → 简单本身是好的，而不是由于简单导致准确度更好&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;The conclusion is that simpler hypotheses should be preferred because
simplicity is a virtue in its own right, not because of a hypothetical
connection with accuracy.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_representable-does-not-imply-learnable&quot;&gt;Representable Does not imply Learnable&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Given finite data, time and memory, standard learners can learn only
a tiny subset of all possible functions, and these subsets are different
for learners with different representations.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_correlation-doesnt-imply-causation&quot;&gt;Correlation Doesn’t Imply Causation&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;相关不是因果&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但学习相关至少是有用的&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Machine learning is usually applied to observational data, where the
predictive variables are not under the control of the learner, as
opposed to experimental data, where they are. Some learning algorithms
can potentially extract causal information from observational data, but
their applicability is rather restricted.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;On the other hand, correlation is a sign of a potential causal
connection, and we can use it as a guide to further investigation (for
example, trying to understand what the causal chain might be).&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;是否存在真正的因果是个哲学问题， 但对于机器学习而言:&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;First, whether or not we call them ``causal,'' we would like to predict
the effects of our actions, not just correlations between observable
variables. Second, if you can obtain experimental data (for example by
randomly assigning visitors to different versions of a Web site), then
by all means do so.14&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name></author><summary type="html">对于 A Few Useful Things to Know about Machine Learning 的总结,这是一篇很有启发的文章,总结了机器学习领域一些本质且普遍的概念.</summary></entry><entry><title type="html">Normalization Techniques</title><link href="https://victarry.github.io/2021/03/14/normalization-techniques.html" rel="alternate" type="text/html" title="Normalization Techniques" /><published>2021-03-14T00:00:00+00:00</published><updated>2021-03-14T00:00:00+00:00</updated><id>https://victarry.github.io/2021/03/14/normalization-techniques</id><content type="html" xml:base="https://victarry.github.io/2021/03/14/normalization-techniques.html">&lt;div id=&quot;toc&quot; class=&quot;toc&quot;&gt;
&lt;div id=&quot;toctitle&quot;&gt;Table of Contents&lt;/div&gt;
&lt;ul class=&quot;sectlevel1&quot;&gt;
&lt;li&gt;&lt;a href=&quot;#_normalization方法概述&quot;&gt;1. Normalization方法概述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#_batch-normalization&quot;&gt;2. Batch Normalization&lt;/a&gt;
&lt;ul class=&quot;sectlevel2&quot;&gt;
&lt;li&gt;&lt;a href=&quot;#_motivation&quot;&gt;2.1. Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#_方法用于cnn中的batchnorm&quot;&gt;2.2. 方法(用于CNN中的Batchnorm)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#_好处&quot;&gt;2.3. 好处&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#_相关论文&quot;&gt;2.4. 相关论文&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#_instance-normalizationn&quot;&gt;3. Instance Normalizationn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#_layer-normalization&quot;&gt;4. Layer Normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#_本文参考文献&quot;&gt;5. 本文参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;自2015年 &lt;em&gt;Batch Normalization&lt;/em&gt; 提出之后, 各种Normalization的technique相继被提出和应用, 例如被广泛用于RNN的Layer Normalizatoin, 用于style transfer的instance Nomalization,以及出身于style transfer后被StyleGAN带火的 &lt;strong&gt;AdaIN&lt;/strong&gt;.
这篇文章作为Normalization Techniques的总结和分析.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_normalization方法概述&quot;&gt;1. Normalization方法概述&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Normalization主要分为Unconditional Norm和Conditional Norm, Unconditional Norm主要用于加速训练, 使模型训练更加稳定;
Conditional Norm多用于生成模型中调制(Modulate)输入信号, 使输出与控制信号相关联, 例如Style Transfer中AdaIN使得输出图像的style与style image相似.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Normalization Technique主要分为两步, 第一部分是对输入进行归一化, 将均值归0, 方差设置为0; 第二步是对标准化后的activations进行transform, 具体的transform可以通过learnable parameters或者conditional signal进行控制, 提高模型的表达能力.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;Unconditional Norm&lt;/p&gt;
&lt;div class=&quot;olist loweralpha&quot;&gt;
&lt;ol class=&quot;loweralpha&quot; type=&quot;a&quot;&gt;
&lt;li&gt;
&lt;p&gt;Whitening transformation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BatchNorm(BN)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instance Norm(IN)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Layer Norm(LN)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Group Norm(GN)
..&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Conditional Norm&lt;/p&gt;
&lt;div class=&quot;olist loweralpha&quot;&gt;
&lt;ol class=&quot;loweralpha&quot; type=&quot;a&quot;&gt;
&lt;li&gt;
&lt;p&gt;Conditional BatchNorm(CBN)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Conditional InstanceNorm(CIN)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_batch-normalization&quot;&gt;2. Batch Normalization&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_motivation&quot;&gt;2.1. Motivation&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;以下出自 &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;原始论文&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;quoteblock&quot;&gt;
&lt;blockquote&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. (本质)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&quot;quoteblock&quot;&gt;
&lt;blockquote&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. (后果)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&quot;quoteblock&quot;&gt;
&lt;blockquote&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. (方法)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&quot;quoteblock&quot;&gt;
&lt;blockquote&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Batch Normalization allows us to use much higher learning rates and be less careful about initialization. (好处)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;梯度反传的一个问题在于, 随着上一层layer的参数的变化,下一层的梯度优化方向也变化了,但神经网络的各个层的参数是同时进行优化的. 其中一个解决办法就是通过normalization来限制上一层输出的范围,从而使训练更稳定.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;为什么要用batch的均值和方差作为normalization时的transform参数呢?  理论上最好统计整个数据集的statistics, 但实际场景中我们只能得到训练集的数据, 所以永远无法统计得到真正的均值和方差,因此用batch的statistics来近似数据的statistics.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;为什么在normalization之后要使用 \(\alpha, \beta\) 来进行affine transformation呢? 论文中给出的解释是, 为了提高模型的表达能力, 至少需要让该模块能够表示 identity transformation, 因此需要\(\alpha, \beta\)做为learnable parameters.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_方法用于cnn中的batchnorm&quot;&gt;2.2. 方法(用于CNN中的Batchnorm)&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;对于 &lt;code&gt;NCHW&lt;/code&gt; 中位置为 &lt;em&gt;(i, j, x, y)&lt;/em&gt; 的tensor, \(x_{ijxy}\), 得到的norm之后的结果为:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[y_{ijxy} = \frac{x_{ijxy} - \mu_{j}}{\sigma_j}  + \beta\]
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;对于channel数为 &lt;code&gt;C&lt;/code&gt; 的tensor, \(\alpha\)和\(\beta\)的数量也为C&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inference时不再使用batch中的均值和方差, 而是使用在训练过程通过running average方法得到的训练数据的均值和方差.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在Pytorch中, &lt;code&gt;nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)&lt;/code&gt;, 设置 &lt;code&gt;affine=Flase&lt;/code&gt; 可以取消使用\(\alpha\)和\(\beta\), 设置 &lt;code&gt;tracking_running_stats=False&lt;/code&gt; 可以使inference时也使用batch的statistics.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_好处&quot;&gt;2.3. 好处&lt;/h3&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;加速训练&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对初始化和learning rate不敏感, 可以使用更大的learning rate&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;作为正则化，提高模型泛化性（可以替代dropout)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以使用saturating nonlinearities作为activation functoin&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Batchnorm广泛使用之后, Dropout的出现就很少了&amp;#8230;&amp;#8203;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_相关论文&quot;&gt;2.4. 相关论文&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/em&gt; 2015, ICML &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;arxiv&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_instance-normalizationn&quot;&gt;3. Instance Normalizationn&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_layer-normalization&quot;&gt;4. Layer Normalization&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_本文参考文献&quot;&gt;5. 本文参考文献&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Normalization Techniques in Training DNNs: Methodology, Analysis and Application&lt;/em&gt; &lt;a href=&quot;https://arxiv.org/abs/2009.12836&quot;&gt;arxiv&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name></author><summary type="html">自2015年 Batch Normalization 提出之后, 各种Normalization的technique相继被提出和应用, 例如被广泛用于RNN的Layer Normalizatoin, 用于style transfer的instance Nomalization,以及出身于style transfer后被StyleGAN带火的 AdaIN. 这篇文章作为Normalization Techniques的总结和分析.</summary></entry><entry><title type="html">原始GAN的优化函数为什么要使用 \(\max \log(D(G(z)))\)</title><link href="https://victarry.github.io/2021/03/10/gan-objective.html" rel="alternate" type="text/html" title="原始GAN的优化函数为什么要使用 \(\max \log(D(G(z)))\)" /><published>2021-03-10T00:00:00+00:00</published><updated>2021-03-10T00:00:00+00:00</updated><id>https://victarry.github.io/2021/03/10/gan-objective</id><content type="html" xml:base="https://victarry.github.io/2021/03/10/gan-objective.html">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;原始GAN的优化目标为:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/gan-objective.png&quot; alt=&quot;gan objective&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;原文中表示在优化G的时候需要重新定义优化目标, 把&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[\min log(1-D(G(z))) \ \ \ \ \ \ \ \ \ (1)\]
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;换为&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[\max log(D(G(z))) \ \ \ \ \ \ \ \ (2)\]
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;quoteblock&quot;&gt;
&lt;blockquote&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In practice, equation 1 may not provide sufﬁcient gradient for G to learn well. Early in learning, when G is poor, D can reject samples with high conﬁdence because they are clearly different from the training data. In this case, log(1 − D(G(z))) saturates. Rather than training G to minimize log(1 − D(G(z))) we can train G to maximize log D(G(z)). This objective function results in the same ﬁxed point of the dynamics of G and D but provides much stronger gradients early in learning.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;这段话对初学者来说并不直观, 下面解释一下:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;GAN在训练前期时, Discriminator往往要强于Generator, 那么对于fake的输入, Discriminator输出的概率往往接近于0, 相应的logit就接近负无穷, logit对应的梯度非常小, 那么反传到generator时得到的梯度也非常小.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;把Discriminator中最后的sigmoid激活函数显式代入到优化目标, 并假设x是\(D(G(z))\)在经过sigmoid得到的 &lt;em&gt;unbouned logit&lt;/em&gt; ,
那么式(1)变为:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[\min \log(1-\sigma (x)) = \min \log(\frac{e^{-x}}{1+e^{-x}}) = \min - \log(1+e^{x})\]
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;对应图像为:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/gan-graph1.png&quot; alt=&quot;gan graph1&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;可以看出, x特别小时, 对应的梯度也特别小&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;式(2)变为:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[\max \log(sigma(x)) = \max - \log (1+e^{-x})\]
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;对应图像为:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/gan-graph2.png&quot; alt=&quot;gan graph2&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;可以看出, x特别小时, 对应梯度很大, 因此generator得到的梯度也很大, 可以加快训练速度&lt;/p&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name><email>nkulzh16@gmail.com</email></author><summary type="html">原始GAN的优化目标为:</summary></entry><entry><title type="html">Semantic Image Synthesis with Spatially-Adaptive Normalization</title><link href="https://victarry.github.io/2021/03/07/SPADE-CVPR-2019.html" rel="alternate" type="text/html" title="Semantic Image Synthesis with Spatially-Adaptive Normalization" /><published>2021-03-07T00:00:00+00:00</published><updated>2021-03-07T00:00:00+00:00</updated><id>https://victarry.github.io/2021/03/07/SPADE-CVPR-2019</id><content type="html" xml:base="https://victarry.github.io/2021/03/07/SPADE-CVPR-2019.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1903.07291&quot;&gt;&lt;em&gt;Semantic Image Synthesis with Spatially-Adaptive Normalization&lt;/em&gt;&lt;/a&gt; Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan Zhu. CVPR 2019(oral)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;div class=&quot;title&quot;&gt;标题分析:&lt;/div&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;semantic image synthsis&lt;/strong&gt; 指出了论文对应的任务, 也就是将semantic map转换为realistic images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;spatially-adaptive normliazation&lt;/strong&gt; 指出了论文的contribution, &lt;strong&gt;&lt;em&gt;spatially-adaptive&lt;/em&gt;&lt;/strong&gt; 表示对不同location进行不同的处理.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;论文评价:
简单的思路, 优秀的效果, 中规中矩的实验分析.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_previous-work&quot;&gt;1. Previous Work&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;Semantic Image Synthesis:&lt;/p&gt;
&lt;div class=&quot;olist loweralpha&quot;&gt;
&lt;ol class=&quot;loweralpha&quot; type=&quot;a&quot;&gt;
&lt;li&gt;
&lt;p&gt;Pix2pix&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pix2pixHD&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Style Transfer:&lt;/p&gt;
&lt;div class=&quot;olist loweralpha&quot;&gt;
&lt;ol class=&quot;loweralpha&quot; type=&quot;a&quot;&gt;
&lt;li&gt;
&lt;p&gt;TODO: style transfer中的normalization进行affine transform吗?(例如fast style transfer)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;之前工作的问题:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;无法生成multi-modal的结果&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;semantic map的信息在upsample过程中容易丢失, normalization layers会 &lt;em&gt;wash away&lt;/em&gt; semantic information.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_motivation&quot;&gt;2. Motivation&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Spatially Adaptive意味着每个location可以进行不同的transform, 不同于batch-norm, instance-norm等对整个channel进行相同的normalization(和transform).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Motivation来源(推测):
. StyleGAN
. Conditional normalization
    .. TODO&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_method&quot;&gt;3. Method&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_spatially-adaptive-denormalization&quot;&gt;3.1. Spatially-adaptive denormalization&lt;/h3&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/spade.png&quot; alt=&quot;300&quot; width=&quot;300&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SPADE的由来&lt;/strong&gt;: SPatially-Adaptive (DE)normalization&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;为什么叫做denormalization?&lt;/strong&gt; :  conditional batchnormalization会利用external data对normalized actiavtions进行denormalize, denormalization本身是conditional.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;如何实现?&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;olist loweralpha&quot;&gt;
&lt;ol class=&quot;loweralpha&quot; type=&quot;a&quot;&gt;
&lt;li&gt;
&lt;p&gt;normalizatoin&lt;/p&gt;
&lt;div class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;经典的convolution中的batchnorm, 对于 &lt;code&gt;NCHW&lt;/code&gt; 的一个batch, 求 &lt;code&gt;C&lt;/code&gt; 个 &lt;code&gt;N*H*W&lt;/code&gt; 的tensor的mean和variance, 并进行normalization&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;spatial-adaptive affine transformation:&lt;/p&gt;
&lt;div class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;根据不同scale大小的semantic map求出大小为 &lt;code&gt;CHW&lt;/code&gt; 的\$\gamma\$和\$\beta\$, 然后进行乘法和加法操作&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;与(Conditional) Batchnorm的联系&lt;/p&gt;
&lt;div class=&quot;olist loweralpha&quot;&gt;
&lt;ol class=&quot;loweralpha&quot; type=&quot;a&quot;&gt;
&lt;li&gt;
&lt;p&gt;normalization过程相同&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但与batch-norm不同的是, affine transformation是会对不同location求出不同的参数&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;与AdaIN(Adaptive Instance Normalization)的联系&lt;/p&gt;
&lt;div class=&quot;exampleblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;把mask替换为style image, 变为spatially-invariant, 设置N=1, 就得到了AdaIN&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_why-does-the-spade-work-better&quot;&gt;3.2. Why does the SPADE work better?&lt;/h3&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;如果一个semantic map在不同位置的值都相同, 那么传统pix2pixHD在conv之后得到的tensor的值在各个位置也相同, instance norm之后, 得到的值都变为0. 对于semantic map这种uniform分布较多的情景, 容易丢失semantic map的信息.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于SPADE, normalization的是activation, 而最初的输入时表示style的tensor(不会想semantic map一样uniform分布), 因此SPADE能更好的保留semantic information.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_multi-modal-synthesis&quot;&gt;3.3. Multi-modal Synthesis&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;问题: 类似的分离style的multi-modal synthesis的范式和原理是什么? TODO
. pix2pix HD
. multi-modal I2I
. starGAN&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_implementation&quot;&gt;4. Implementation&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/spade-arch.png&quot; alt=&quot;spade arch&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;title&quot;&gt;Figure 1. Architecture of SPADE generator&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_model&quot;&gt;4.1. Model&lt;/h3&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_generator&quot;&gt;4.1.1. Generator&lt;/h4&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/spade-generator.png&quot; alt=&quot;400&quot; width=&quot;400&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;div class=&quot;title&quot;&gt;设计原则&lt;/div&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;输入为latent vector和semantic map&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;generator为SPADEResnetBlock和Upsample层的交替叠加&lt;/p&gt;
upsample替代transpose-convolution的工作越来越多, 这样可以减少artifact的产生
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;实现代码&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;tok-nc&quot;&gt;SPADEGenerator&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;BaseNetwork&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;tok-nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-nf&quot;&gt;modify_commandline_options&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;is_train&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;set_defaults&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_G&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;spectralspadesyncbatch3x3&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;--num_upsampling_layers&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;tok-n&quot;&gt;choices&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;normal&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;more&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;most&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;normal&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;tok-n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-s2&quot;&gt;&amp;quot;If &amp;#39;more&amp;#39;, adds upsampling layer between the two middle resnet blocks. If &amp;#39;most&amp;#39;, also add one more upsampling + resnet layer at the end of the generator&amp;quot;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;parser&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;ngf&lt;/span&gt;


        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sw&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;compute_latent_vector_size&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;

        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;use_vae&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-c1&quot;&gt;# In case of VAE, we will sample from random z vector&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;z_dim&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sw&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sh&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;b class=&quot;conum&quot;&gt;(2)&lt;/b&gt;
        &lt;span class=&quot;tok-k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-c1&quot;&gt;# Otherwise, we make the network deterministic by starting with&lt;/span&gt;
            &lt;span class=&quot;tok-c1&quot;&gt;# downsampled segmentation map instead of random z&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;semantic_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;b class=&quot;conum&quot;&gt;(2)&lt;/b&gt;

        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;head_0&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADEResnetBlock&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;G_middle_0&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADEResnetBlock&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;G_middle_1&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADEResnetBlock&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_0&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADEResnetBlock&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;8&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_1&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADEResnetBlock&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;8&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_2&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADEResnetBlock&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_3&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADEResnetBlock&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;final_nc&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_upsampling_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;most&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_4&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADEResnetBlock&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;final_nc&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nf&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt;

        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_img&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;final_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Upsample&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;scale_factor&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-nf&quot;&gt;compute_latent_vector_size&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_upsampling_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;normal&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;num_up_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;5&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_upsampling_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;more&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;num_up_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;6&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_upsampling_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;most&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;num_up_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;7&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;opt.num_upsampling_layers [&lt;/span&gt;&lt;span class=&quot;tok-si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;] not recognized&amp;#39;&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;%&lt;/span&gt;
                             &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_upsampling_layers&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;sw&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;crop_size&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_up_layers&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sw&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;aspect_ratio&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;sw&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;sh&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;input&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;use_vae&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-c1&quot;&gt;# we sample z from unit normal and reshape the tensor&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;tok-kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;tok-n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;z_dim&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;tok-n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;get_device&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;())&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;ngf&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sh&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sw&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-c1&quot;&gt;# we downsample segmap and run convolution&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;interpolate&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sh&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;sw&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;head_0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;G_middle_0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_upsampling_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;more&amp;#39;&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;or&lt;/span&gt; \
           &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_upsampling_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;most&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;G_middle_1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_2&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_3&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;num_upsampling_layers&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;most&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;up_4&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_img&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;leaky_relu&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mf&quot;&gt;2e-1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;latent vector size是根据什么计算的?
在图像大小的基础上, 每个upsample layer, 将width除2, height根据aspect ratio决定&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;16对应的是什么?
last conv layer和first conv layer的channel个数的倍数是16, nf是最后一个conv层的filter数量&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_spaderesblock&quot;&gt;4.2. SPADEResBlock&lt;/h3&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/SPADEResBlock.png&quot; alt=&quot;400&quot; width=&quot;400&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;title&quot;&gt;Figure 2. SPADEResBlock&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;与传统ResBlock相似, 2个Conv加上skip-connection&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;learned skip connection来自于参考文献3&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每个Conv层使用 &lt;strong&gt;spectral normalization&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为什么resblock最后不加ReLU呢? TODO&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;实现代码&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;tok-nc&quot;&gt;SPADEResnetBlock&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fin&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fout&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;tok-c1&quot;&gt;# Attributes&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;learned_shortcut&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;fin&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fout&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;fmiddle&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;fin&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fout&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-c1&quot;&gt;# create conv layers&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_0&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;fin&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fmiddle&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_1&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;fmiddle&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fout&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;learned_shortcut&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_s&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;fin&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fout&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-c1&quot;&gt;# apply spectral norm if specified&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;spectral&amp;#39;&lt;/span&gt; &lt;span class=&quot;tok-ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_G&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_0&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;spectral_norm&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_1&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;spectral_norm&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;learned_shortcut&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_s&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;spectral_norm&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_s&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-c1&quot;&gt;# define normalization layers&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;spade_config_str&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_G&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;spectral&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_0&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADE&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;spade_config_str&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fin&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;semantic_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_1&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADE&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;spade_config_str&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fmiddle&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;semantic_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;learned_shortcut&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_s&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SPADE&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;spade_config_str&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;fin&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;semantic_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;tok-c1&quot;&gt;# note the resnet block with SPADE also takes in |seg|,&lt;/span&gt;
    &lt;span class=&quot;tok-c1&quot;&gt;# the semantic segmentation map as input&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;x_s&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;shortcut&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;actvn&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_0&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;actvn&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)))&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x_s&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;dx&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;out&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-nf&quot;&gt;shortcut&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;learned_shortcut&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;x_s&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;conv_s&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_s&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;x_s&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x_s&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-nf&quot;&gt;actvn&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;leaky_relu&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-mf&quot;&gt;2e-1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_spade实现&quot;&gt;4.3. SPADE实现&lt;/h3&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/spade-module.png&quot; alt=&quot;400&quot; width=&quot;400&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;segment map的shape怎么和activation对齐? nearest-neighbour下采样 (order=0, order为1是线性插值)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sync Batch Norm是干什么的? Pytorch中 &lt;code&gt;nn.DataParallel&lt;/code&gt; 在多个GPU下训练时分别使用单个device的statistics进行normalize(这样会更快), sync batch norm实现使用所有device中的数据来求statistics,  &lt;a href=&quot;https://github.com/vacancy/Synchronized-BatchNorm-PyTorch&quot;&gt;参考链接&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;SPADE实现代码&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;tok-nc&quot;&gt;SPADE&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;config_text&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;norm_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;label_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;tok-nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;config_text&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;startswith&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;spade&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;parsed&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;spade(\D+)(\d)x\d&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;config_text&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;param_free_norm_type&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;parsed&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;ks&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;parsed&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;param_free_norm_type&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;instance&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;param_free_norm&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;InstanceNorm2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;affine&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;param_free_norm_type&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;syncbatch&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;param_free_norm&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;SynchronizedBatchNorm2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;affine&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;param_free_norm_type&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;batch&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;param_free_norm&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;norm_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;affine&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;tok-k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;tok-ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt; is not a recognized param-free norm type in SPADE&amp;#39;&lt;/span&gt;
                             &lt;span class=&quot;tok-o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;param_free_norm_type&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-c1&quot;&gt;# The dimension of the intermediate embedding space. Yes, hardcoded.&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;nhidden&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;128&lt;/span&gt;

        &lt;span class=&quot;tok-n&quot;&gt;pw&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;ks&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;mlp_shared&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;label_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nhidden&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;ks&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;pw&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;mlp_gamma&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;nhidden&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;norm_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;ks&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;pw&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;mlp_beta&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;nhidden&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;norm_nc&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;ks&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;pw&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;tok-k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;tok-nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;segmap&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;tok-c1&quot;&gt;# Part 1. generate parameter-free normalized activations&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;normalized&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;param_free_norm&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-c1&quot;&gt;# Part 2. produce scaling and bias conditioned on semantic map&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;segmap&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;interpolate&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;segmap&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;tok-s1&quot;&gt;&amp;#39;nearest&amp;#39;&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;
        &lt;span class=&quot;tok-n&quot;&gt;actv&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;mlp_shared&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;segmap&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;mlp_gamma&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;actv&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;tok-o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;mlp_beta&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-n&quot;&gt;actv&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;tok-c1&quot;&gt;# apply scale and bias&lt;/span&gt;
        &lt;span class=&quot;tok-n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;normalized&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;tok-p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;tok-mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;tok-o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;beta&lt;/span&gt;

        &lt;span class=&quot;tok-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;tok-n&quot;&gt;out&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;interpolate使得semantic map和x的长宽相同&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_discriminator&quot;&gt;4.4. Discriminator&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;采用pix2pixHD的设计结构&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_objective&quot;&gt;4.5. Objective&lt;/h3&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;GAN loss: hinge loss&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feature Mathching Loss&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VGG perceptual loss&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_代码技巧&quot;&gt;4.6. 代码技巧&lt;/h3&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;div class=&quot;title&quot;&gt;TODO&lt;/div&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;options的结构&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;find module by name&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_experiment&quot;&gt;5. Experiment&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_对比工作&quot;&gt;5.1. 对比工作&lt;/h3&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;pix2pixHD&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CRN&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SIMS&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_ablation-study&quot;&gt;5.2. Ablation Study&lt;/h3&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_effectivenss-of-the-spade&quot;&gt;5.2.1. Effectivenss of the SPADE&lt;/h4&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/spade-ablation1.png&quot; alt=&quot;spade ablation1&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_variations-of-spade&quot;&gt;5.2.2. Variations of SPADE&lt;/h4&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/spade-ablation2.png&quot; alt=&quot;spade ablation2&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;输入noise还是segmap: 区别不大,说明了SPADE可以有效嵌入semantic map的信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生成\$\alpha, \beta\$ 时用的conv的kernel size: 1x1的时候效果较差,说明&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;normalization type: 影响不大&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;generator中filters数量导致的params的个数: 参数量的提高不一定会带来明显的性能提升&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_reference-paper&quot;&gt;6. Reference Paper&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;A learned representation for artistic style. 2017 (conditional batchnorm)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Modulating early visual processing by language. 2017&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Which Training Methods for GANs do actually Converge? 2018 (ResBlock)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Geometric GAN(hinge loss)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_单词时间&quot;&gt;7. 单词时间&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;seminal: strongly influencing later developments; 开创性的&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt; &lt;strong&gt;Seminal&lt;/strong&gt; work computes the output image by stitching pieces from a single image (e.g., Image Analogies [16]) or using an image collection [7, 14, 23, 30, 35]&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;modulate: exert a modifying or controlling influence on; 调制(信号学术语)&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt; To address the issue, we propose spatially-adaptive normalization, a conditional normalization layer that &lt;strong&gt;modulates&lt;/strong&gt; the activations using input semantic layouts through a spatiallyadaptive, learned transformation and can effectively propagate the semantic information throughout the network. &lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name></author><summary type="html">Semantic Image Synthesis with Spatially-Adaptive Normalization Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan Zhu. CVPR 2019(oral)</summary></entry><entry><title type="html">Introduction to PGM</title><link href="https://victarry.github.io/2021/02/26/Introduction-to-PGM.html" rel="alternate" type="text/html" title="Introduction to PGM" /><published>2021-02-26T00:00:00+00:00</published><updated>2021-02-26T00:00:00+00:00</updated><id>https://victarry.github.io/2021/02/26/Introduction-to-PGM</id><content type="html" xml:base="https://victarry.github.io/2021/02/26/Introduction-to-PGM.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;这篇文章作为 &lt;a href=&quot;https://www.ece.iastate.edu/~namrata/EE527_Spring12/lgraphical1.pdf&quot;&gt;An Introduction to PGM, Jodan&lt;/a&gt; 的简单总结.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_条件独立conditional-independance&quot;&gt;条件独立(Conditional Independance)&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_基本定义&quot;&gt;基本定义&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;条件独立的定义&lt;/strong&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;对于随机变量\(X, Y, Z\), 在给定Z的情况下, X和Y条件独立, 记作 \(X \perp Y \mid Z\), 当且仅当:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[f_{X, Y \mid Z}(x, y \mid z) = f_{X \mid Z}(x \mid z)f_{Y \mid Z}(y \mid z)\]
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;条件独立的等价形式&lt;/strong&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[X \perp Y \mid Z\]
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;当且仅当:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[f_{X \mid Y,Z}(x \mid y,z) = f_{X \mid Z}(x \mid z)\]
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;summary class=&quot;title&quot;&gt;证明如下&lt;/summary&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;如果&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[\begin{align}
f(x, y \mid z) = f(x \mid z)f(y \mid z) &amp;amp; \Leftrightarrow \frac{f(x, y, z)}{f(z)} = \frac{f(x, y)}{f(z)} \frac{f(y, z)}{f(z)}  \\
                         &amp;amp; \Leftrightarrow \frac{f(x, y, z)}{f(y, z)} = \frac{f(x, y)}{f(z)} \\
                         &amp;amp; \Leftrightarrow f(x \mid y, z) = f(x, z)

\end{align}\]
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_条件独立的推论&quot;&gt;条件独立的推论&lt;/h3&gt;
&lt;div class=&quot;stemblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
\[\begin{eqnarray}
\tag{1}
X \perp Y \mid Z &amp;amp; \Rightarrow &amp;amp; Y \perp X \mid Z \\
\tag{2}
Y \perp X \mid Z &amp;amp; \Rightarrow &amp;amp; Y \perp h(X) \mid Z  \\
\tag{3}
Y \perp X \mid Z &amp;amp; \Rightarrow &amp;amp; Y \perp X \mid \{Z, h(X)\}  \Leftrightarrow Y \perp \{X, h(X)\} \mid Z \\
\tag{4}
Y \perp X \mid Z &amp;amp; \ \ and \ \ &amp;amp; W \perp X\ \mid\ \{Y, Z\} \Rightarrow \{Y, W\} \perp X \mid Z \\
\tag{5}
Y \perp X \mid Z &amp;amp; and &amp;amp; Z \perp X \mid Y \Rightarrow \{Y, Z\} \perp X
\end{eqnarray}\]
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;summary class=&quot;title&quot;&gt;证明2&lt;/summary&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary class=&quot;title&quot;&gt;证明3&lt;/summary&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary class=&quot;title&quot;&gt;证明4&lt;/summary&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary class=&quot;title&quot;&gt;证明5&lt;/summary&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;(3) 中 \(Y \perp X \mid \{Z, h(X)\}  \Leftrightarrow Y \perp \{X, h(X)\} \mid Z\)  可采用条件独立的等价形式进行证明&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_directed-graphical-models&quot;&gt;Directed Graphical Models&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_定义&quot;&gt;定义&lt;/h3&gt;

&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_图-概率分布的函数&quot;&gt;图 &amp;#8658; 概率分布的函数&lt;/h3&gt;

&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_图-分布中蕴含的条件独立&quot;&gt;图 &amp;#8658; 分布中蕴含的条件独立&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_undirected-pgm&quot;&gt;Undirected PGM&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name></author><summary type="html">这篇文章作为 An Introduction to PGM, Jodan 的简单总结.</summary></entry><entry><title type="html">在MacOS下使用Docker运行GUI</title><link href="https://victarry.github.io/2021/02/21/run-gui-in-docker-of-MacOS.html" rel="alternate" type="text/html" title="在MacOS下使用Docker运行GUI" /><published>2021-02-21T00:00:00+00:00</published><updated>2021-02-21T00:00:00+00:00</updated><id>https://victarry.github.io/2021/02/21/run-gui-in-docker-of-MacOS</id><content type="html" xml:base="https://victarry.github.io/2021/02/21/run-gui-in-docker-of-MacOS.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;在Docker内运行GUI程序需要利用 &lt;a href=&quot;https://en.wikipedia.org/wiki/X_Window_System&quot;&gt;X_Window_System&lt;/a&gt; , MacOS下对应的实现是Xquartz.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_安装socat&quot;&gt;1. 安装socat&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;brew install socat
socat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT:\&quot;$DISPLAY\&quot; &amp;amp; &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Xquartz的listen 端口为6000&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_安装xquartz&quot;&gt;2. 安装Xquartz&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;在 &lt;a href=&quot;https://www.xquartz.org/&quot; class=&quot;bare&quot;&gt;https://www.xquartz.org/&lt;/a&gt; 网站上下载并安装Xquartz&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;xhost + &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;
docker run -e DISPLAY=host.docker.internal:0 gns3/xeyes &lt;b class=&quot;conum&quot;&gt;(2)&lt;/b&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;允许所有其他ip地址的客户端连接到xquartz&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.docker.com/docker-for-mac/networking/#per-container-ip-addressing-is-not-possible&quot;&gt;host.docker.internal&lt;/a&gt; 是一个Docker Desktop for MAC专用的nameserver, 可以解析出host对应的ip&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;如果成功的话,就可以看到一个眼睛的界面&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/xeyes.png&quot; alt=&quot;test&quot; width=&quot;300&quot; height=&quot;300&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;title&quot;&gt;Figure 1. 运行成功的结果&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_参考链接&quot;&gt;2.1. 参考链接&lt;/h3&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@mreichelt/how-to-show-x11-windows-within-docker-on-mac-50759f4b65cb&quot; class=&quot;bare&quot;&gt;https://medium.com/@mreichelt/how-to-show-x11-windows-within-docker-on-mac-50759f4b65cb&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://cntnr.io/running-guis-with-docker-on-mac-os-x-a14df6a76efc&quot; class=&quot;bare&quot;&gt;https://cntnr.io/running-guis-with-docker-on-mac-os-x-a14df6a76efc&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name></author></entry><entry><title type="html">使用AsciiDoc在Github-Pages上搭建博客</title><link href="https://victarry.github.io/2021/02/17/asciidoc-jekyll-githubpage-tutorial.html" rel="alternate" type="text/html" title="使用AsciiDoc在Github-Pages上搭建博客" /><published>2021-02-17T00:00:00+00:00</published><updated>2021-02-17T00:00:00+00:00</updated><id>https://victarry.github.io/2021/02/17/asciidoc-jekyll-githubpage-tutorial</id><content type="html" xml:base="https://victarry.github.io/2021/02/17/asciidoc-jekyll-githubpage-tutorial.html">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;本文介绍了如何使用AsciiDoc代替Markdown写文章,并通过 &lt;em&gt;Travis-ci&lt;/em&gt; 将AsciiDoc生成为html,最后发布到Github-Pages上.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;由于没有找到详细介绍AsciiDoc构建Github-Pages的中文资源, 因此本文记录了笔者关于搭建博客的整个过程.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_为什么要使用asciidoc&quot;&gt;1. 为什么要使用AsciiDoc?&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://asciidoctor.org/docs/what-is-asciidoc/&quot;&gt;AsciiDoc&lt;/a&gt;和Markdown一样,是一种轻量级标记语言,用于简单的文章排版和页面生成.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Markdown虽然方便,但功能相对较少,不如AsciiDoc强大.
Wikipedia列举了
&lt;a href=&quot;https://en.wikipedia.org/wiki/Lightweight_markup_language#Comparison_of_language_features&quot;&gt;不同标记语言的对比&lt;/a&gt;
,可以看出AsciiDoc是功能最完善的标记语言之一.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.asciidoctor.org/asciidoc/latest/asciidoc-vs-markdown/&quot;&gt;AsciiDoc官方列举了AsciiDoc和markdown的对比&lt;/a&gt;
，其中AsciiDoc相对于Markdown的优势有:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;相同标记场景下, AsciiDoc用的字符数要比Markdown更少.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AsciiDoc的格式更加统一.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AsciiDoc可以处理任意排列的inline嵌套格式,而Markdown经常难以处理.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AsciiDoc可以处理一些Markdown无法处理的场景, 例如单词内的标记, Block-level源代码和block-level images.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;与markdown一样的是,&lt;strong&gt;Github仓库预览时支持AsciiDoc&lt;/strong&gt;, 也就是说在github写README,wiki和gist时可以使用AsciiDOc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;但是,&lt;strong&gt;Github-Pages官方不支持AsciiDoc的Jekyll插件&lt;/strong&gt;,
因此无法直接上传AsciiDoc文件生成Github-Pages网站,但我们可以用 &lt;em&gt;Travis&lt;/em&gt; 自动build的工具生成asciidoc对应的html文件.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_asciidocjekyll博客本地配置&quot;&gt;2. AsciiDoc+Jekyll博客本地配置&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_jekyll安装&quot;&gt;2.1. Jekyll安装&lt;/h3&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;安装ruby, &lt;a href=&quot;https://www.ruby-lang.org/en/downloads/&quot;&gt;下载链接&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装Jekyll并新建网站&lt;/p&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;~ $ gem install bundler jekyll
~ $ jekyll new my-awesome-site
~ $ cd my-awesome-site
~/my-awesome-site $ bundle exec jekyll serve&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用浏览器打开 &lt;a href=&quot;http://localhost:4000&quot; class=&quot;bare&quot;&gt;http://localhost:4000&lt;/a&gt; 查看博客&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_jekyll文件结构&quot;&gt;2.2. Jekyll文件结构&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;在 &lt;code&gt;my-awesome-site&lt;/code&gt; 文件夹下面,可以看到运行 &lt;code&gt;jekyll new my-awesome-site&lt;/code&gt; 初始化生成的所有文件.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;├── &lt;span class=&quot;tok-m&quot;&gt;404&lt;/span&gt;.html
├── Gemfile  &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;
├── Gemfile.lock
├── _config.yml  &lt;b class=&quot;conum&quot;&gt;(2)&lt;/b&gt;
├── _posts  &lt;b class=&quot;conum&quot;&gt;(3)&lt;/b&gt;
│   └── &lt;span class=&quot;tok-m&quot;&gt;2021&lt;/span&gt;-02-17-welcome-to-jekyll.markdown
├── about.markdown &lt;b class=&quot;conum&quot;&gt;(4)&lt;/b&gt;
└── index.markdown  &lt;b class=&quot;conum&quot;&gt;(4)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;配置所需要的包和依赖, 例如Jekyll本身的包&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;关于博客网站级别的配置,例如网站&lt;em&gt;theme&lt;/em&gt;, &lt;em&gt;baseurl&lt;/em&gt;和相关插件&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有在 &lt;code&gt;_posts&lt;/code&gt; 文件夹下的markdown文件都会作为Post类型的页面来渲染.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有在根目录下的markdown文件都会作为Page类型的页面来渲染&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Jekyll通过将markdown文件渲染成静态html文件来生成博客网站的主体内容,其中页面分为两个类别,
分别是&lt;strong&gt;Page&lt;/strong&gt;和&lt;strong&gt;Post&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pages是Jekyll中用于撰写内容的最基本单元, Pages适合用于单独的内容, 也就是与日期无关并且不是成组的内容.&lt;/p&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;如果要添加一个新的Page, 只需要在根目录下添加一个新的HTML文件或者Markdown文件, 例如包含了about, index和contact页面的文件及其对应的URL如下:&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;    .
    ├── about.md    # =&amp;gt; http://example.com/about.html
    ├── index.html    # =&amp;gt; http://example.com/
    └── contact.html  # =&amp;gt; http://example.com/contact.html&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Posts正如博客中的文章,可以方便记录书写时间,并且统一展示起来. 与Pages同样, 既可以使用HTML,也可以使用Markdown,
需要注意的是文件必须命名为 &lt;strong&gt;&lt;code&gt;YYYY-MM-DD-title-of-post.markdown&lt;/code&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_asciidoc安装配置&quot;&gt;2.3. AsciiDoc安装配置&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Jekyll可以直接支持Markdown的渲染, 为了使用AsciiDoc代替Makrdown, 我们要使用Jekyll-AsciiDoc的插件&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_在gemfile中添加jekyll-asciidoc的依赖&quot;&gt;2.3.1. 在Gemfile中添加Jekyll-AsciiDoc的依赖&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;在 &lt;code&gt;Gemfile&lt;/code&gt; 中找到 &lt;code&gt;group :jekyll_plugins do&lt;/code&gt; , 并加入 &lt;code&gt;gem 'jekyll-asciidoc'&lt;/code&gt;,
得到如下 &lt;code&gt;Gemfile&lt;/code&gt; 文件:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;source &quot;https://rubygems.org&quot;
# Hello! This is where you manage which Jekyll version is used to run.
# When you want to use a different version, change it below, save the
# file and run `bundle install`. Run Jekyll with `bundle exec`, like so:
#
#     bundle exec jekyll serve
#
# This will help ensure the proper Jekyll version is running.
# Happy Jekylling!
gem 'jekyll', '~&amp;gt; 3.8.3'
# This is the default theme for new Jekyll sites. You may change this to anything you like.
gem &quot;minima&quot;
# If you want to use GitHub Pages, remove the &quot;gem &quot;jekyll&quot;&quot; above and
# uncomment the line below. To upgrade, run `bundle update github-pages`.
# gem &quot;github-pages&quot;, group: :jekyll_plugins
# If you have any plugins, put them here!
group :jekyll_plugins do
  gem 'jekyll-asciidoc'
end&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_激活jekyll-asciidoc插件可选&quot;&gt;2.3.2. 激活jekyll-asciidoc插件(可选)&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;修改 &lt;code&gt;_config.yml&lt;/code&gt; 文件, 找到 &lt;code&gt;plugins:&lt;/code&gt; , 添加 &lt;code&gt;jekyll-asciidoc&lt;/code&gt; , 从而激活asciidoc插件&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;plugins:
  - jekyll-asciidoc&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;由于jekyll会自动激活 &lt;code&gt;:jekyll_plugins&lt;/code&gt; 组中的插件,因此该步骤也可以省略.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_重新生成jekyll网站&quot;&gt;2.3.3. 重新生成jekyll网站&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;运行以下命令&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;bundle install
bundle &lt;span class=&quot;tok-nb&quot;&gt;exec&lt;/span&gt; jekyll serve --livereload &lt;span class=&quot;tok-c1&quot;&gt;# --livereload可以自动更新页面&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;在根目录或者 &lt;code&gt;_posts&lt;/code&gt; 下添加 &lt;code&gt;.adoc&lt;/code&gt; 文件,就可以看到新生成的页面.
这样,就可以用AsciiDoc代替Markdown来写Pages或者Posts了,只需要用 &lt;code&gt;.adoc&lt;/code&gt; 文件替换 &lt;code&gt;.md&lt;/code&gt; 文件.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;至此,就成功在本地使用AsciiDoc撰写个人博客网站了,下一部分内容会讲述如何将博客通过Github-Pages发布到互联网上.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_jekyll和asciidoc参考链接&quot;&gt;2.4. jekyll和AsciiDoc参考链接&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://asciidoctor.org/#installation&quot;&gt;AsciiDoc安装&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/asciidoctor/asciidoctor-vscode&quot;&gt;AsciiDoc Vscode插件&lt;/a&gt;, 可以直接预览AsciiDoc文件&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://asciidoctor.org/docs/asciidoc-writers-guide/&quot;&gt;AsciiDoc Writing Guide&lt;/a&gt;, 快速上手AsciiDoc&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.asciidoctor.org/asciidoc/latest/&quot;&gt;AsciiDoc Documentation&lt;/a&gt;, AsciiDoc详细介绍&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.asciidoctor.org/asciidoc/latest/syntax-quick-reference/&quot;&gt;AsciiDoc语法查询手册&lt;/a&gt;, 可以快速查询AsciiDoc对应的语法&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://jekyllrb.com/docs/&quot;&gt;jekyll Documentation&lt;/a&gt;, jekyll详细介绍&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/asciidoctor/jekyll-asciidoc&quot;&gt;jekyll-AsciiDoc插件&lt;/a&gt;, 用于在jekyll中使用AsciiDoc&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/asciidoctor/jekyll-asciidoc-quickstart&quot;&gt;jekyll-AsciiDoc-Quickstart&lt;/a&gt;, 可以直接在github上Fork, 相当于使用配置好的AsciiDoc-jekyll网站,这样就不需要从头开始,并且手动修改关于AsciiDoc的相关配置了.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_github-pages配置&quot;&gt;3. Github-Pages配置&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;新建一个仓库,仓库名设置为 &lt;code&gt;USERNAME.github.io&lt;/code&gt; , github会自动为该repo启用github-pages&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将新建的网站文件夹加入git, 并push到github远程仓库上&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;~/my-awesome-site $ git init
~/my-awesome-site $ git add --all
~/my-awesome-site $ git commit -m &quot;First commit&quot;
~/my-awesome-site $ git remote add git@github.com:USERNAME/USERNAME.github.io
~/my-awesome-site $ git push -u origin master&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;详细可参考 &lt;a href=&quot;https://docs.github.com/en/github/working-with-github-pages/creating-a-github-pages-site-with-jekyll&quot;&gt;Github-Pages官方教程&lt;/a&gt;, 但不需要启用github-pages的gem包.&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;之后就可以在 &lt;a href=&quot;https://USERNAME.github.io&quot; class=&quot;bare&quot;&gt;https://USERNAME.github.io&lt;/a&gt; 上查看新建的博客, 对于markdown写的文章,可以正确渲染. 但对于AsciiDoc写的文章,无法正确查看. 由于 &lt;a href=&quot;https://github.com/asciidoctor/jekyll-asciidoc#using-this-plugin-on-github-pages&quot;&gt;Github-Pages没有将 &lt;code&gt;jekyll-AsciiDoc&lt;/code&gt; 的插件加入到白名单中&lt;/a&gt;, 因此我们需要采用CI来完成AsciiDoc文件的渲染.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_使用ci进行构建和上传&quot;&gt;4. 使用CI进行构建和上传&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_method-1-使用github-actions进行自动构建-推荐&quot;&gt;Method 1. 使用Github Actions进行自动构建 (推荐)&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;在`USERNAME.github.io`的repo下面，新建``.github/workflows`文件夹, 并新建文件`github-pages.yml`文件并填入:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;pygments highlight&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;tok-nt&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;Build and deploy Jekyll site to GitHub Pages&lt;/span&gt;

&lt;span class=&quot;tok-nt&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;tok-nt&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;branches&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;tok-p tok-p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;master&lt;/span&gt;

&lt;span class=&quot;tok-nt&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;tok-nt&quot;&gt;github-pages&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;runs-on&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class=&quot;tok-nt&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;tok-p tok-p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;tok-nt&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;actions/checkout@v3&lt;/span&gt;
      &lt;span class=&quot;tok-p tok-p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;tok-nt&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;actions/cache@v2&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;tok-nt&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;vendor/bundle&lt;/span&gt;
          &lt;span class=&quot;tok-nt&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;${{ runner.os }}-gems-${{ hashFiles(&amp;#39;**/Gemfile&amp;#39;) }}&lt;/span&gt;
          &lt;span class=&quot;tok-nt&quot;&gt;restore-keys&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-p tok-p-Indicator&quot;&gt;|&lt;/span&gt;
            &lt;span class=&quot;tok-no&quot;&gt;${{ runner.os }}-gems-&lt;/span&gt;
      &lt;span class=&quot;tok-p tok-p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;tok-nt&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;helaili/jekyll-action@v2&lt;/span&gt;
        &lt;span class=&quot;tok-nt&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;tok-nt&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;${{ secrets.GITHUB_TOKEN }}&lt;/span&gt;
          &lt;span class=&quot;tok-nt&quot;&gt;pre_build_commands&lt;/span&gt;&lt;span class=&quot;tok-p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;tok-l tok-l-Scalar tok-l-Scalar-Plain&quot;&gt;apk --update add python3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;然后，在github上对应的repo &amp;#8594; setting &amp;#8594; Options &amp;#8594; Github-Pages中设置branch为 &lt;code&gt;gh-pages&lt;/code&gt; 并save.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;关于github actions的详细内容，参见 &lt;a href=&quot;https://docs.github.com/en/actions&quot;&gt;github actions docs&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_method-2-使用travis配置&quot;&gt;Method 2. 使用Travis配置&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;我们可以通过Travis-CI调用Rake-jekyll来构建jekyll网站并上传到对应的仓库中.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_配置rake-jekyll&quot;&gt;4..1. 配置Rake-jekyll&lt;/h4&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;将 &lt;code&gt;gem 'rake-jekyll', '~&amp;gt; 1.1.0'&lt;/code&gt; 加入到 &lt;code&gt;Gemfile&lt;/code&gt; 中&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;新建 &lt;code&gt;Rakefile&lt;/code&gt; 文件, 并将下面内容复制到其中&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;require 'rake-jekyll'

# This task builds the Jekyll site and deploys it to a remote Git repository.
# It's preconfigured to be used with GitHub and Travis CI.
# See http://github.com/jirutka/rake-jekyll for more options.
Rake::Jekyll::GitDeployTask.new(:deploy) do |t|
    t.committer = 'Jekyll Publisher &amp;lt;jekyll@example.com&amp;gt;'
    t.deploy_branch = 'gh-pages'
end&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重新安装依赖
&lt;code&gt;bundle install&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们可以直接运行 &lt;code&gt;bundle exec rake deploy&lt;/code&gt; 来将渲染好的网站push到github远程仓库中的 &lt;code&gt;gh-pages&lt;/code&gt; 分支上.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在github上对应的repo &amp;#8594; setting &amp;#8594; Options &amp;#8594; Github-Pages中设置branch为 &lt;code&gt;gh-pages&lt;/code&gt; 并save.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们再次打开 &lt;a href=&quot;https://USERNAME.github.io&quot; class=&quot;bare&quot;&gt;https://USERNAME.github.io&lt;/a&gt; , 就可以看到使用AsciiDoc撰写的文章了&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;但这样每次更新博客都要手动调用 &lt;code&gt;bundle exec rake deploy&lt;/code&gt; , 我们可以通过Travis-CI帮我们自动完成这一任务.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_配置travis-ci&quot;&gt;4..2. 配置Travis-CI&lt;/h4&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;登录 &lt;a href=&quot;https://travis-ci.com/&quot; class=&quot;bare&quot;&gt;https://travis-ci.com/&lt;/a&gt; 网站, 使用github账号登录并且进行Permission的授权&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 &lt;a href=&quot;https://travis-ci.com/account/repositories&quot; class=&quot;bare&quot;&gt;https://travis-ci.com/account/repositories&lt;/a&gt; 中进行 sync, 将对应的 repo 加入到Travis-CI管理的项目中.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;新建 &lt;code&gt;.travis.yml&lt;/code&gt; 文件,  将以下内容复制到文件中&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;language: ruby
rvm: 2.7.2
os: osx
before_install:
  - gem install bundler
install: bundle install --deployment
script: bundle exec rake deploy&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;我的电脑系统为MacOS Big Sur, 为了保持环境一致设置了 &lt;code&gt;os: osx&lt;/code&gt; , 也可以设置为 &lt;code&gt;os: linux&lt;/code&gt; 等, 但不同情况可能会遇到不同的问题, &lt;strong&gt;注意看错误信息&lt;/strong&gt; .&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装travis&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;gem install -n /usr/local/bin travis&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 &lt;a href=&quot;https://github.com/settings/tokens/new&quot; class=&quot;bare&quot;&gt;https://github.com/settings/tokens/new&lt;/a&gt; 中生成新的token, 可以设置合适的权限&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将github token加密写入到 &lt;code&gt;.travis.yml&lt;/code&gt; 文件中&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;travis encrypt GH_TOKEN=&amp;lt;above token&amp;gt; --add env.global --com&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;(这一步可能需要使用命令行登录)&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将所有文件更新commit并且push到github上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 &lt;a href=&quot;https://travis-ci.com/&quot; class=&quot;bare&quot;&gt;https://travis-ci.com/&lt;/a&gt; 中查看build的log&lt;/p&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/travis-screenshot.png&quot; alt=&quot;travis build结果&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;build成功的话就可以在 &lt;a href=&quot;https://USERNAME.github.io&quot; class=&quot;bare&quot;&gt;https://USERNAME.github.io&lt;/a&gt; 中看到生成的网站&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_其他问题&quot;&gt;5. 其他问题&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_显示latex公式&quot;&gt;5.1. 显示latex公式&lt;/h3&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_添加mathjax-link&quot;&gt;5.1.1. 添加mathjax link&lt;/h4&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;新建_includes/mathjax.html, 并将下列代码复制到文件中&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;&amp;lt;script type=&quot;text/x-mathjax-config&quot;&amp;gt;
MathJax.Hub.Config({
  messageStyle: &quot;none&quot;,
  tex2jax: {
    inlineMath: [[&quot;\\(&quot;, &quot;\\)&quot;]],
    displayMath: [[&quot;\\[&quot;, &quot;\\]&quot;]],
    ignoreClass: &quot;nostem|nolatexmath&quot;
  },
  asciimath2jax: {
    delimiters: [[&quot;\\$&quot;, &quot;\\$&quot;]],
    ignoreClass: &quot;nostem|noasciimath&quot;
  },
  TeX: { equationNumbers: { autoNumber: &quot;none&quot; } }
});
&amp;lt;/script&amp;gt;
&amp;lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_HTMLorMML&quot;&amp;gt;&amp;lt;/script&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在layout模板中的 &lt;code&gt;&amp;lt;body&amp;gt; &amp;lt;/body&amp;gt;&lt;/code&gt; 内include上述文件, 如果添加到 &lt;code&gt;default&lt;/code&gt; 的layout中, 那么可以新建 &lt;code&gt;_layouts/default.html&lt;/code&gt;, 复制下列代码&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang=&quot;{{ page.lang | default: site.lang | default: &quot;en&quot; }}&quot;&amp;gt;

  {%- include head.html -%}

  &amp;lt;body&amp;gt;

    {%- include mathjax.html -%}
    {%- include header.html -%}

    &amp;lt;main class=&quot;page-content&quot; aria-label=&quot;Content&quot;&amp;gt;
      &amp;lt;div class=&quot;wrapper&quot;&amp;gt;
        {{ content }}
      &amp;lt;/div&amp;gt;
    &amp;lt;/main&amp;gt;

    {%- include footer.html -%}

  &amp;lt;/body&amp;gt;

&amp;lt;/html&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_在asciidoc中添加公式&quot;&gt;5.1.2. 在AsciiDoc中添加公式&lt;/h4&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;启用stem, 在 &lt;a href=&quot;https://docs.asciidoctor.org/asciidoc/latest/document/metadata/&quot;&gt;metadata&lt;/a&gt; 中加入:&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;:stem:&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用行内公式(inline formula)&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;stem:[C = \alpha + \beta Y^{\gamma} + \epsilon]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用块公式(block formula)&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;[stem]
++++
C = \alpha + \beta Y^{\gamma} + \epsilon
++++&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_代码高亮&quot;&gt;5.2. 代码高亮&lt;/h3&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;在 &lt;code&gt;Gemfile&lt;/code&gt; 中添加pygments依赖&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;gem 'pygments.rb', '~&amp;gt; 2.1.0'&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 &lt;code&gt;_config.yml&lt;/code&gt; 中添加下列代码&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;asciidoctor:
  attributes:
  - idprefix=_
  - source-highlighter=pygments
  - pygments-css=class
  - pygments-stylesheet=css/asciidoc-pygments.css&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在theme对应的template中的 &lt;code&gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&lt;/code&gt; tag下加入 &lt;code&gt;asciidoc-pygments.css&lt;/code&gt; 作为stylesheet&lt;/p&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;&amp;lt;link href=&quot;/css/asciidoc-pygments.css&quot; rel=&quot;stylesheet&quot;&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_mardown和asciidoc转换工具&quot;&gt;5.3. Mardown和Asciidoc转换工具&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://tinyapps.org/blog/201701240700_convert_asciidoc_to_markdown.html&quot; class=&quot;bare&quot;&gt;https://tinyapps.org/blog/201701240700_convert_asciidoc_to_markdown.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_further-reading&quot;&gt;6. Further Reading&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_静态网站&quot;&gt;6.1. 静态网站&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt;: Ruby 语言编写的静态网站博客生成器，由 GitHub 所创造和维护，支持 Markdown、HTML、Liquid 等多种语言和模板引擎。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://gohugo.io/&quot;&gt;Hugo&lt;/a&gt;: Go 语言编写的静态网站博客生成器，速度很快，支持多种格式的内容和模板引擎。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;: JavaScript 语言编写的静态网站博客生成器，基于 Node.js 平台，支持多种主题和插件。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://getpelican.com/&quot;&gt;Pelican&lt;/a&gt;: Python 语言编写的静态网站博客生成器，支持多种格式的内容和主题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://www.gatsbyjs.com/starters/gatsbyjs/gatsby-starter-blog&quot;&gt;Gatsby&lt;/a&gt;：基于 React.js 的静态网站生成器，使用 GraphQL 查询数据，支持多种主题和插件。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_博客发布平台&quot;&gt;6.2. 博客发布平台&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://ghost.org/&quot;&gt;Ghost&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Medium&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_动态网站&quot;&gt;6.3. 动态网站&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;http://typecho.org/&quot;&gt;typecho&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;WordPress&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Zhenhuan Liu</name></author></entry></feed>